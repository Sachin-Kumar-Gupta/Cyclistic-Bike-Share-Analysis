# -*- coding: utf-8 -*-
"""Cyclistic Bike-Share Analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10XLuC_8Jk1OGAY-mRwbYgdDDDIYcJ0tN

# ***🧠 Ask: Define the Business Task***

## About Company :

Cyclistic is a bike-share offering company. Under a program they offer 5,824 bicycles that are geotracked and locked into a network of 692 stations across Chicago. The bikes can be unlocked from one station and returned to any other station in the system anytime.
Until now, Cyclistic’s marketing strategy relied on building general awareness and appealing to
broad consumer segments. One approach that helped make these things possible was the
flexibility of its pricing plans: single-ride passes, full-day passes, and annual memberships.

**Customers who purchase single-ride or full-day passes are referred to as casual riders.**

**Customers who purchase annual memberships are Cyclistic members**

## Business Goal

Design marketing strategies aimed at converting casual riders into annual members. In order to do that, however, the team needs to better understand how
annual members and casual riders differ, why casual riders would buy a membership, and how
digital media could affect their marketing tactics.

 Moreno and her team are interested in
analyzing the Cyclistic historical bike trip data to identify trends.

## Key Stakeholders :

* ***Lily Moreno :*** The director of marketing who is responsible for developing campaigns and initiatives to promote the bike-sharing program.
* ***Cyclistic marketing analytics team :*** This team is responsible for collecting, analyzing, and reporting data that guides Cyclistic's marketing strategy.
* ***Cyclistic's executive team :*** This detail-oriented executive team will decide whether to approve the recommended marketing program.

## Questions to be answered :

1. How do annual members and casual riders use Cyclistic bikes differently?
2. Why would casual riders buy Cyclistic annual memberships?
3. How can Cyclistic use digital media to influence casual riders to become members?

# Importing libraries
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px

"""# ***Prepare phase : Load and Understand the data***

***Data Credibility and Bias:***

As the data is provided by the company that operates the bike-sharing service, it should be considered as reliable. However, we must be aware that the data could contain biases based on operational constraints or data collection methods. For example, the data only includes people who have chosen to use the Cyclistic service and might not represent the entire population of bike riders in Chicago.

***Data Integrity:***

The data's integrity will be verified by performing exploratory data analysis (EDA) to identify any inconsistencies or missing values in dataset.

## Loading Dataset
"""

df = pd.read_csv("merged_cyclistic_dataset.csv")
df.head(5)

# Backing up original data
main_df = df.copy()

df.info()

"""Start_at and End_at should be in date time format but showing it as object, so we need to change them.
Also we need to change the end_lng to float from object type.
"""

# Converting columns to correct type
df['started_at'] = pd.to_datetime(df['started_at'], errors='coerce')
df['ended_at'] = pd.to_datetime(df['ended_at'], errors='coerce')
df['end_lng']   = df['end_lng'].astype(float)

df.describe(include='object')

# Checking for duplicate rows
df.duplicated().sum()

df.isnull().sum()

"""Columns like start_station_name, start_station_id, end_station_name and end_station_id have large missing values. Also meber_casual, end_lat and end_lng have few missing values.
Let's check for how much percatnge of data is missing in them.
"""

# Missing value summary
missing = pd.DataFrame({'column': df.columns,'total_count': len(df),'missing_count': df.isnull().sum()})
missing['missing_pct'] = (missing['missing_count'] / missing['total_count']) * 100
# Interactive bar chart of missing values
fig = px.bar(missing,x='column',y='missing_pct',title='Missing Value Percentage by Column',
             labels={'missing_pct': '% Missing'})
fig.update_layout(xaxis_tickangle=-45)
fig.show()

"""Approx 19% data is missing from start and end station name and id columns.

We need to further analysis this to decide whether to drop this missing data or replace it.
"""

# Get all categorical (object type) columns
cat_cols = df.select_dtypes(include='object').columns.tolist()
# Unique values in each
cat_summary = pd.DataFrame({'column': cat_cols,'unique_values': [df[col].nunique() for col in cat_cols]})
cat_summary

"""***Conclusion:***

The dataset contains key categorical features:

**rideable_type**: Low cardinality (3 unique values) — good for grouping.

**member_casual:** Binary user classification — useful for segmentation.

**start_station_name & end_station_name:** High cardinality (~1000+) — can be noisy; better used for top N analysis rather than modeling directly.

**ride_id:** Unique identifier, not useful for grouping.

# ***Process phase : Clean and Transform the data***

## Analyzing for missing values

We have null values in :
* started_at
* ended_at
* start_station_name
* start_station_id
* end_station_name
* end_station_id
* end_lat
* end_lng
"""

# Group by lat/lng
grouped = df.groupby(['start_lat', 'start_lng'])
# Create a summary: count how many rows are missing vs non-missing in each group
summary = grouped['start_station_name'].agg([('total_rows', 'count'),('missing_count', lambda x: x.isna().sum()),
    ('non_missing_count', lambda x: x.notna().sum()),
     ('unique_station_names', lambda x: x.dropna().nunique())]).reset_index()
# Filter: only where some are missing and some are present
candidates = summary[(summary['missing_count'] > 0) & (summary['non_missing_count'] > 0)]
candidates.head(10)  # show top 10 for preview

"""Conclusion : We did'nt found any column where station name is avilable and missing for same start latitute and longitute. Now lets check on basis of station id."""

# Group by ID and count missing vs not missing names
id_summary = df.groupby('start_station_id')['start_station_name'].agg([('total_rows', 'count'),
    ('missing_count', lambda x: x.isna().sum()),('non_missing_count', lambda x: x.notna().sum()),
    ('unique_station_names', lambda x: x.dropna().nunique())]).reset_index()
# Filter: where some names are missing and some are present
id_candidates = id_summary[(id_summary['missing_count'] > 0) & (id_summary['non_missing_count'] > 0)]
id_candidates.head()

# Group by lat/lng
grouped = df.groupby(['end_lat', 'end_lng'])
# Create a summary: count how many rows are missing vs non-missing in each group
summary_end = grouped['end_station_name'].agg([
    ('total_rows', 'count'),('missing_count', lambda x: x.isna().sum()),
     ('non_missing_count', lambda x: x.notna().sum()),
    ('unique_station_names', lambda x: x.dropna().nunique())]).reset_index()

# Filter: only where some are missing and some are present
candidates_end = summary_end[(summary_end['missing_count'] > 0) & (summary_end['non_missing_count'] > 0)]

candidates_end.head(10)  # show top 10 for preview

# Group by ID and count missing vs not missing names
id_summary_end = df.groupby('end_station_id')['end_station_name'].agg([('total_rows', 'count'),
    ('missing_count', lambda x: x.isna().sum()),('non_missing_count', lambda x: x.notna().sum()),
    ('unique_station_names', lambda x: x.dropna().nunique())]).reset_index()
# Filter: where some names are missing and some are present
id_candidates_end = id_summary_end[(id_summary_end['missing_count'] > 0) & (id_summary_end['non_missing_count'] > 0)]
id_candidates_end.head()

"""***Conclusion:***

Since no matching station names could be inferred using either station id or (lat, lng) for start and end station name both, we can label missing values as 'Unknown' to retain those rows for general analysis.
"""

# For start
df[df['start_station_id'].isna() != df['start_station_name'].isna()]

# For end
df[df['end_station_id'].isna() != df['end_station_name'].isna()]

"""*** Conclusion :***

 Station name and station id for both start and end always have missing values in the same rows, indicating that missingness occurs at the ride level, not just in naming inconsistencies.
"""

df[df['end_lat'].isna() != df['end_lng'].isna()]

"""End_lat and end_lng both have null values in same rows, now lets check for do they have end_station_name and same name have end_lat and end_lng in dataset or not."""

missing_coords = df[df['end_lat'].isna() | df['end_lng'].isna()]
missing_coords['end_station_name'].isna().value_counts()

"""## Handling Missing Values

As we didn't found any strong evidence to fill null values of Staion names and IDs for start and end, we are replacing them with "Unknown".
"""

df['start_station_name'] = df['start_station_name'].fillna('Unknown')
df['start_station_id'] = df['start_station_id'].fillna('Unknown')
df['end_station_name'] = df['end_station_name'].fillna('Unknown')
df['end_station_id'] = df['end_station_id'].fillna('Unknown')

"""We can't replace date time variables as it will give false results and missing values are only 0.09%, so we are droping them from dataset."""

df = df[df['started_at'].notna() & df['ended_at'].notna()]

"""For missing values in end_lat and end_lng we have also missing station name, so we have to drop null values."""

df = df[df['end_lat'].notna() & df['end_lng'].notna()]

df.isnull().sum()

"""Now, we don't have null value in our dataset, so we can now analyse dataset.

# ***Analyze phase : Explore the data and discover patterns.***

## ***E.D.A.***

Befor analysing dataset let's make some derived column usefull for analysis.
"""

# Ride duration in minutes
df['ride_duration_min'] = (df['ended_at'] - df['started_at']).dt.total_seconds() / 60
# Time features
df['hour'] = df['started_at'].dt.hour
df['day_of_week'] = df['started_at'].dt.day_name()
df['month'] = df['started_at'].dt.strftime('%b')
df['is_roundtrip'] = df['start_station_name'] == df['end_station_name']

pip install haversine

# Trip distance
from haversine import haversine
df['distance_km'] = df.apply(lambda row: haversine((row['start_lat'], row['start_lng']),
    (row['end_lat'], row['end_lng'])), axis=1)

df[['ride_duration_min', 'distance_km']].describe()

"""***⚠️ Anomalies Detected:***
* Minimum Ride duration is less than 1 minute and maximum duration is 1499 minutes approx 25 hours.
* Minimum distance traveled is 0 km and maximum distance is 5758 km which seems quite not possible.
"""

cleaned_df = df[(df['ride_duration_min'] > 0.5) &(df['ride_duration_min'] < 1440) &
            (df['distance_km'] > 0.1) &(df['distance_km'] < 100)]

"""***Q1. How do annual members and casual riders use Cyclistic bikes differently?***

***Q2. Why would casual riders buy Cyclistic annual memberships?***

***Q3. How can Cyclistic use digital media to influence casual riders to become members?***

To answer this questions we have to analyse the pattern of uses of rides by member and casual users.

### Let's explore dataset first.
"""

# Ride Counts by User Type
fig = px.histogram(cleaned_df,x='member_casual',color='member_casual',title='Total Rides by User Type',
                   labels={'member_casual': 'User Type', 'count': 'Ride Count'},text_auto=True)
fig.show()

"""***Conclusion:***

Member users take more rides overall than casual users, indicating higher platform engagement from subscribed users. This aligns with expectations as members likely use bikes for daily commuting or routines.
"""

# Ride Counts by Bike Type and User Type
fig = px.histogram(cleaned_df,x = 'rideable_type',color = 'member_casual',barmode = 'group',title='Bike Type Usage by User Type',
                   labels={'member_casual': 'User Type', 'rideable_type': 'Bike Type'},text_auto=True)
fig.show()

"""***Conclusion:***

*   Both, member and casual users prefer electric bikes, but members tend to use them slightly more.

*   Classic bikes are also used significantly, especially by members.

*   Electric scooters have the least usage and casual member use it slightly higher than members.
"""

fig = px.histogram(cleaned_df,x = 'day_of_week',color = 'member_casual',
                   category_orders={'day_of_week': ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']},
                   barmode='group',labels = {'member_casual':'User Type','count':'Ride counts'},
                   text_auto = True)
fig.show()

"""***Conclusion:***

* Casual users ride more on weekends (Saturday and Sunday) — suggesting recreational use.

* Members ride more on weekdays, peaking around midweek — consistent with work/commute patterns.
"""

# Plotting Ride volume Vs Hour of day
fig = px.histogram(cleaned_df,x='hour',color='member_casual',barmode='group',title='Ride Volume by Hour of Day',
                   labels={'hour': 'Hour of Day', 'count': 'Ride Count'},text_auto=True)
fig.show()

"""***Conclusion:***

* Members ride more during morning (7–9 AM) and evening (4–6 PM), aligning with commute hours.

* Casual users ride more during afternoons (12-5 PM)and weekends, suggesting leisure usage.
"""

# Ride duration in minutes
duration_stats = cleaned_df.groupby('member_casual')['ride_duration_min'].agg(['mean', 'median', 'max', 'count']).round(2)
plt.figure(figsize=(8,5))
sns.boxplot(data=cleaned_df, x='member_casual', y='ride_duration_min')
plt.ylim(0, 60)  # cap outliers for readability
plt.title("Ride Duration (Minutes) by User Type")
plt.show()

"""The boxplot shows that casual riders tend to take significantly longer rides than members. This pattern suggests that frequent casual riders could benefit from an annual membership to reduce per-ride costs, especially for long-duration trips."""

# Roundtrips (% of rides starting and ending at same station)
roundtrip_pct = cleaned_df.groupby('member_casual')['is_roundtrip'].mean().multiply(100).round(2)
roundtrip_pct

# Seasonal Trends
monthly = cleaned_df.groupby(['member_casual', 'month']).size().reset_index(name='ride_count')
# To maintain calendar order
month_order = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun','Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']
fig = px.bar(monthly,x='month',y='ride_count',color='member_casual',category_orders={'month': month_order},
    title='Monthly Ride Count by User Type',
    labels={'month': 'Month', 'ride_count': 'Number of Rides', 'member_casual': 'User Type'},text_auto=True)
fig.update_layout(barmode='group', template='plotly_white')
fig.show()

"""***Conclusion:***
* Casual riders exhibit strong seasonal patterns, peaking in the summer and early fall. This suggests recreational use driven by good weather and leisure time.

* Members, on the other hand, maintain a relatively stable ride count throughout the year, pointing to habitual use such as daily commutes or consistent travel needs.

* Cyclistic’s marketing could target casual riders more heavily in spring/summer, promoting seasonal passes or weekend packages, and promote year-round savings and convenience to convert them into members.
"""

# Top 10 starting station
top_start_stations = (cleaned_df[cleaned_df['start_station_name'] != 'Unknown']
    .groupby(['member_casual', 'start_station_name']).size().reset_index(name='ride_count')
    .sort_values(['member_casual', 'ride_count'], ascending=False).groupby('member_casual')  # group again to get top 10 per type
    .head(10))
fig = px.bar(top_start_stations,x='ride_count',y='start_station_name',color='member_casual',orientation='h',
    facet_col='member_casual',title='Top 10 Start Stations by User Type',
    labels={'ride_count': 'Number of Rides','start_station_name': 'Start Station','member_casual': 'User Type'},
             height=600)

fig.update_layout(yaxis={'categoryorder':'total ascending'}, template='plotly_white')
fig.show()

# Top 10 end station
top_end_stations = (cleaned_df[cleaned_df['end_station_name'] != 'Unknown']
    .groupby(['member_casual', 'end_station_name']).size().reset_index(name='ride_count')
    .sort_values(['member_casual', 'ride_count'], ascending=False).groupby('member_casual')  # group again to get top 10 per type
    .head(10))
fig = px.bar(top_end_stations,x='ride_count',y='end_station_name',color='member_casual',orientation='h',
    facet_col='member_casual',title='Top 10 End Stations by User Type',
    labels={'ride_count': 'Number of Rides','end_station_name': 'End Station','member_casual': 'User Type'},
    height=600)
fig.update_layout(yaxis={'categoryorder':'total ascending'}, template='plotly_white')
fig.show()

"""***Conclusion:***

🚴 Casual riders typically start and end their trips at Chicago's scenic hotspots, confirming a pattern of leisure-oriented, seasonal usage.

🚴‍♂️ Members consistently use stations near downtown, offices, and commuter hubs, showing routine, practical use, likely for daily transportation.

These patterns can inform targeted ads:

* Promote commute-saving features to frequent casual riders.

* Offer tourist bundle passes for scenic stations.

* Place digital ads near lakefront hotspots to convert casual users.
"""

cleaned_df.groupby('member_casual')['distance_km'].describe()

"""🧠 Interpretation:
* Both user groups have very similar average distances per ride(around 2.3 km), which may indicate the general city biking range.

* Median distances are slightly lower (~1.64 km for members, ~1.76 km for casuals), indicating a right-skewed distribution — meaning a small number of longer rides pull up the average.

* Standard deviation is slightly higher for casual riders (1.95 vs. 1.94), showing more variation in casual trip lengths.

* Maximum distances (over 90 km) are still quite large and may represent edge cases like recreational tours or potential GPS inaccuracies

# ***Share & Act phase : Answering Key Business Questions.***

## ***Ans 1.***

***Casual riders demonstrate strong recreational behavior:***

* They ride longer, mostly on weekends and holidays.

* Prefer starting at scenic spots (e.g., Millennium Park, Lake Shore Drive).

* Their usage is weather-dependent and peaks in summer months.

***Annual members show commuter-style behavior:***

* Use bikes more regularly, even in colder months.

* Prefer practical, short-distance trips to/from work or public transport.

* Start and end at locations closer to business hubs and transit corridors.

## ***Ans 2.***

* Casual riders tend to take longer rides and ride more frequently on weekends and they travel more specially in summer months. These patterns suggest a preference for recreational use. Since many top stations are shared between members and casuals, the infrastructure already supports a smooth transition.

* By analyzing ride durations, we can say that casual riders often take trips of more duration than members which can be economical with a membership plan, especially for frequent users. Introducing seasonal promotions, weekend commuter bundles, or discounted trial memberships could appeal to these users.

In summary, by addressing pricing, convenience, and seasonal trends, Cyclistic can position membership as a more valuable and cost-effective option for high-engagement casual riders.

## ***Ans 3.***

* Based on ride patterns, Cyclistic should target casual riders with weekend, summer, and long-ride offers.
* Digital ads on Instagram, Facebook, and Google should emphasize value-for-money, ease of use, and comfort. A seasonal campaign offers can increase conversion.
* Geo-targeted ads near high-traffic stations from where casual start their journey, can further boost effectiveness.
"""